{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83ddad2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Any, Union\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e74bec93",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TranscriptDataManager:\n",
    "    \"\"\"\n",
    "    A class to manage loading, merging, and accessing podcast transcript data.\n",
    "    \"\"\"\n",
    "    def __init__(self, base_path: str = \"..\"):\n",
    "        \"\"\"\n",
    "        Initialize the manager.\n",
    "        \n",
    "        Args:\n",
    "            base_path (str): The directory where the JSON files are located relative to the notebook.\n",
    "        \"\"\"\n",
    "        self.base_path = Path(base_path)\n",
    "        self.data: Dict[str, List[Dict[str, Any]]] = {}\n",
    "\n",
    "    def load_data(self, filenames: List[str]) -> None:\n",
    "        \"\"\"\n",
    "        Loads multiple JSON transcript files and merges them into a single data source.\n",
    "        \n",
    "        Args:\n",
    "            filenames (List[str]): List of filenames to load.\n",
    "        \"\"\"\n",
    "        for filename in filenames:\n",
    "            file_path = self.base_path / filename\n",
    "            if not file_path.exists():\n",
    "                print(f\"Warning: File not found: {file_path.resolve()}\")\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                print(f\"Loading {filename}...\")\n",
    "                with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                    chunk = json.load(f)\n",
    "                    self._merge_chunk(chunk)\n",
    "                print(f\"Successfully loaded {filename}. Total episodes so far: {len(self.data)}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {filename}: {e}\")\n",
    "\n",
    "    def _merge_chunk(self, new_data: Dict[str, List[Dict[str, Any]]]) -> None:\n",
    "        \"\"\"\n",
    "        Merges a new chunk of data into the main dataset.\n",
    "        \n",
    "        Args:\n",
    "            new_data (Dict): Dictionary of episodes to merge.\n",
    "        \"\"\"\n",
    "        # Check for overlaps\n",
    "        existing_keys = set(self.data.keys())\n",
    "        new_keys = set(new_data.keys())\n",
    "        overlap = existing_keys.intersection(new_keys)\n",
    "        \n",
    "        if overlap:\n",
    "            print(f\"Warning: {len(overlap)} episodes overlap and will be overwritten.\")\n",
    "            \n",
    "        self.data.update(new_data)\n",
    "\n",
    "    def get_combined_data(self) -> Dict[str, List[Dict[str, Any]]]:\n",
    "        \"\"\"Returns the raw combined dictionary.\"\"\"\n",
    "        return self.data\n",
    "\n",
    "    def get_all_utterances(self) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Flattens the data structure to return a list of all utterances across all episodes.\n",
    "        Useful for creating RAG chunks.\n",
    "        \"\"\"\n",
    "        all_utterances = []\n",
    "        for episode_id, utterances in self.data.items():\n",
    "            # Optionally inject episode_id into each utterance if not present\n",
    "            for u in utterances:\n",
    "                if 'episode_id' not in u:\n",
    "                    u['episode_id'] = episode_id\n",
    "            all_utterances.extend(utterances)\n",
    "        return all_utterances\n",
    "    \n",
    "    def get_stats(self) -> Dict[str, int]:\n",
    "        \"\"\"Returns basic statistics about the loaded data.\"\"\"\n",
    "        return {\n",
    "            \"total_episodes\": len(self.data),\n",
    "            \"total_utterances\": sum(len(u) for u in self.data.values())\n",
    "        }\n",
    "\n",
    "    def save_to_json(self, output_filename: str) -> None:\n",
    "        \"\"\"\n",
    "        Saves the combined data to a JSON file.\n",
    "        \n",
    "        Args:\n",
    "            output_filename (str): The name of the file to save.\n",
    "        \"\"\"\n",
    "        output_path = self.base_path / output_filename\n",
    "        try:\n",
    "            print(f\"Saving data to {output_path}...\")\n",
    "            with open(output_path, 'w', encoding='utf-8') as f:\n",
    "                json.dump(self.data, f, indent=4)\n",
    "            print(f\"Successfully saved data to {output_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving data: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43db666b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train-transcripts-aligned.json...\n",
      "Successfully loaded train-transcripts-aligned.json. Total episodes so far: 593\n",
      "Loading valid-transcripts-aligned.json...\n",
      "Successfully loaded valid-transcripts-aligned.json. Total episodes so far: 627\n",
      "Loading test-transcripts-aligned.json...\n",
      "Successfully loaded test-transcripts-aligned.json. Total episodes so far: 663\n",
      "\n",
      "Data Loading Complete.\n",
      "Total Episodes: 663\n",
      "Total Utterances: 163808\n",
      "Successfully loaded train-transcripts-aligned.json. Total episodes so far: 593\n",
      "Loading valid-transcripts-aligned.json...\n",
      "Successfully loaded valid-transcripts-aligned.json. Total episodes so far: 627\n",
      "Loading test-transcripts-aligned.json...\n",
      "Successfully loaded test-transcripts-aligned.json. Total episodes so far: 663\n",
      "\n",
      "Data Loading Complete.\n",
      "Total Episodes: 663\n",
      "Total Utterances: 163808\n"
     ]
    }
   ],
   "source": [
    "# Define the files to load\n",
    "files_to_load = [\n",
    "    \"train-transcripts-aligned.json\",\n",
    "    \"valid-transcripts-aligned.json\",\n",
    "    \"test-transcripts-aligned.json\"\n",
    "]\n",
    "\n",
    "# Initialize the manager\n",
    "# Note: The files are in the parent directory relative to this notebook\n",
    "manager = TranscriptDataManager(base_path=\"..\")\n",
    "\n",
    "# Load the files\n",
    "manager.load_data(files_to_load)\n",
    "\n",
    "# Print stats\n",
    "stats = manager.get_stats()\n",
    "print(\"\\nData Loading Complete.\")\n",
    "print(f\"Total Episodes: {stats['total_episodes']}\")\n",
    "print(f\"Total Utterances: {stats['total_utterances']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ada042",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8d23e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data to ../combined_transcripts.json...\n",
      "Successfully saved data to ../combined_transcripts.json\n",
      "Successfully saved data to ../combined_transcripts.json\n"
     ]
    }
   ],
   "source": [
    "# Save the combined data to a new JSON file\n",
    "output_filename = \"combined_transcripts.json\"\n",
    "manager.save_to_json(output_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e87c05a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc5c7e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alignments for first utterance of ep-1:\n",
      "[\n",
      "    [\n",
      "        0.17,\n",
      "        0.45000000000000007,\n",
      "        0\n",
      "    ],\n",
      "    [\n",
      "        0.45000000000000007,\n",
      "        0.5700000000000001,\n",
      "        1\n",
      "    ]\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Inspect the problematic data point\n",
    "ep1_data = manager.data['ep-1']\n",
    "first_utterance = ep1_data[0]\n",
    "print(\"Alignments for first utterance of ep-1:\")\n",
    "print(json.dumps(first_utterance['alignments'], indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6451c2c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found in utterance index 4:\n",
      "[\n",
      "    [\n",
      "        4.45,\n",
      "        4.65,\n",
      "        0\n",
      "    ],\n",
      "    [\n",
      "        4.65,\n",
      "        4.65,\n",
      "        1\n",
      "    ],\n",
      "    [\n",
      "        4.65,\n",
      "        4.65,\n",
      "        2\n",
      "    ],\n",
      "    [\n",
      "        4.65,\n",
      "        4.8500000000000005,\n",
      "        3\n",
      "    ],\n",
      "    [\n",
      "        4.8500000000000005,\n",
      "        4.8500000000000005,\n",
      "        4\n",
      "    ],\n",
      "    [\n",
      "        4.8500000000000005,\n",
      "        4.890000000000001,\n",
      "        5\n",
      "    ],\n",
      "    [\n",
      "        4.890000000000001,\n",
      "        5.45,\n",
      "        6\n",
      "    ],\n",
      "    [\n",
      "        5.45,\n",
      "        5.85,\n",
      "        8\n",
      "    ]\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Find the utterance with the problematic alignment\n",
    "for i, u in enumerate(manager.data['ep-1']):\n",
    "    for align in u.get('alignments', []):\n",
    "        if 8 in align and 5.45 in align:\n",
    "            print(f\"Found in utterance index {i}:\")\n",
    "            print(json.dumps(u['alignments'], indent=4))\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
