{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41c5bef3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain_core.documents import Document\n",
    "from typing import List, Dict, Any\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import tiktoken\n",
    "import chromadb\n",
    "from pinecone import Pinecone\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5286928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ChromaDB from: /Users/matthewlu/Downloads/podcast-RAG/notebooks/../models/tal_chroma\n",
      "Vector store loaded successfully.\n",
      "Vector store loaded successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ChromaDB from: /Users/matthewlu/Downloads/podcast-RAG/notebooks/../models/tal_chroma\n",
      "Vector store loaded successfully.\n",
      "Vector store loaded successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nt/6nrb_d696ylb20nhdcw60rfc0000gn/T/ipykernel_89380/2487074061.py:21: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vector_store = Chroma(\n"
     ]
    }
   ],
   "source": [
    "# LOAD EXISTING VECTOR DATABASE\n",
    "import os\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "import chromadb\n",
    "\n",
    "# 1. Define the path to the existing database\n",
    "persist_dir = os.path.join(os.getcwd(), \"../models/tal_chroma\")\n",
    "print(f\"Loading ChromaDB from: {persist_dir}\")\n",
    "\n",
    "# 2. Initialize the embedding function\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-small\",\n",
    "    openai_api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    ")\n",
    "\n",
    "# 3. Connect to the persistent client\n",
    "client = chromadb.PersistentClient(path=persist_dir)\n",
    "\n",
    "# 4. Load the vector store\n",
    "vector_store = Chroma(\n",
    "    client=client,\n",
    "    collection_name=\"tal_collection\",\n",
    "    embedding_function=embeddings,\n",
    ")\n",
    "\n",
    "print(\"Vector store loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3eb41a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to Pinecone...\n",
      "Vector store loaded successfully from Pinecone.\n"
     ]
    }
   ],
   "source": [
    "# OPTION 2: LOAD PINECONE VECTOR DATABASE\n",
    "# Run this cell INSTEAD of the ChromaDB cell above if you want to use the cloud database.\n",
    "\n",
    "import os\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from pinecone import Pinecone\n",
    "\n",
    "# 1. Initialize the embedding function\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-small\",\n",
    "    openai_api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    ")\n",
    "\n",
    "# 2. Connect to Pinecone\n",
    "print(\"Connecting to Pinecone...\")\n",
    "pc = Pinecone(api_key=os.getenv(\"PINECONE_API_KEY\"))\n",
    "index_name = \"podcast-rag\"\n",
    "\n",
    "# 3. Load the vector store\n",
    "vector_store = PineconeVectorStore(\n",
    "    index_name=index_name,\n",
    "    embedding=embeddings\n",
    ")\n",
    "\n",
    "print(\"Vector store loaded successfully from Pinecone.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46a20a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_utterances': 14, 'act': 'credits', 'num_words': 219, 'roles': 'host, subject', 'speakers': 'adam davidson, alex blumberg, announcer, glen pizzolorusso, ira glass', 'chunk_utterance_start': 3456.93, 'episode': 'ep-355', 'chunk_utterance_end': 3540.00052154195, 'chunk_index': 0}\n",
      "Alex Blumberg and Adam Davidson. Alex, my voice is so bad, I think maybe you should read the credits. Why don't you do it? All right, Ira. I hope you feel better. I'm going to bring Adam in here to help me to, since I've never done this before. Thanks today to Ellen Weiss at NPR who made this collaboration happen this week between the news division at NPR, where I work, All Things Considered, and This American Life. Where I work. Thanks also to Mary Ann Casavant, Anna Chai, Kevin Byers, the fant ...\n",
      "\n",
      "{'num_utterances': 1, 'episode': 'ep-385', 'chunk_index': 0, 'chunk_utterance_end': 3464.92, 'chunk_utterance_start': 3461.47, 'num_words': 13, 'roles': 'host', 'act': 'credits', 'speakers': 'ira glass'}\n",
      "I'm Ira Glass. Back next week with more stories of This American Life. ...\n",
      "\n",
      "{'chunk_index': 3, 'act': 'prologue', 'chunk_utterance_end': 283.66, 'num_utterances': 6, 'num_words': 224, 'roles': 'host, interviewer, subject', 'speakers': 'ira glass, jim biederman', 'chunk_utterance_start': 200.18, 'episode': 'ep-73'}\n",
      "They do? Yes, I'm off to the side right now, but if I go across-- and I'll just do this for you, Ira, because I know that this is real radio here. So I'm going to go over to the other side here. And I'm in the center now, and she's looking straight at me. She's got that enigmatic smile. She looks like she might be smirking a bit at these tourists. I could be wrong. And now I'm over on the left side, and she's still staring at me over here. Well, today on our program, people who thought that they ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "docs = vector_store.similarity_search(\"In episode 462, what did Ira Glass and Steve Blass talk about?\", k=3)\n",
    "for d in docs:\n",
    "    print(d.metadata)\n",
    "    print(d.page_content[:500], \"...\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d7eed03",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model_name=\"gpt-4o-mini\",\n",
    "    temperature=1,\n",
    "    openai_api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    verbose=False,\n",
    "    streaming=False\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca53d5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def classify_intent(question: str):\n",
    "    prompt = f\"\"\"Classify the user's input into one of these categories: GREETING, SPECIFIC_EPISODE_QUERY, GENERAL_KNOWLEDGE.\n",
    "    \n",
    "    - GREETING: Simple salutations like \"hello\", \"hi\", \"good morning\".\n",
    "    - SPECIFIC_EPISODE_QUERY: Questions asking for specific details, stories, quotes, or content found within the episode transcripts. Examples: \"What happened in episode 4?\", \"Stories about love\", \"What did Ira say about...\".\n",
    "    - GENERAL_KNOWLEDGE: General questions about the podcast (host, genre, history) that don't require transcript search, OR questions unrelated to the podcast. Examples: \"What is This American Life?\", \"Who is Ira Glass?\", \"What is 2+2?\".\n",
    "\n",
    "    Input: {question}\n",
    "    \n",
    "    Respond ONLY with the category name.\n",
    "    \"\"\"\n",
    "    return llm.invoke(prompt).content.strip().upper()\n",
    "\n",
    "def ask_podcast_rag(question: str):\n",
    "    # 0. Classify intent using LLM\n",
    "    intent = classify_intent(question)\n",
    "\n",
    "    if \"GREETING\" in intent:\n",
    "        return (\n",
    "            \"Hello! I'm here to help you explore 'This American Life' transcripts. Ask me a question about an episode!\",\n",
    "            [],\n",
    "            None,\n",
    "        )\n",
    "\n",
    "    if \"GENERAL_KNOWLEDGE\" in intent:\n",
    "        return llm.invoke(question).content, [], None\n",
    "\n",
    "    # 1. Try to extract an episode number for metadata filtering\n",
    "    # This helps the vector store narrow down to the specific episode\n",
    "    search_kwargs = {\"k\": 10}\n",
    "    \n",
    "    # Regex to find \"episode <number>\"\n",
    "    match = re.search(r\"episode\\s+(\\d+)\", question, re.IGNORECASE)\n",
    "    filter_used = None\n",
    "    if match:\n",
    "        ep_num = match.group(1)\n",
    "        # Construct the ID format used in your metadata (e.g., \"ep-462\")\n",
    "        filter_dict = {\"episode\": f\"ep-{ep_num}\"}\n",
    "        search_kwargs[\"filter\"] = filter_dict\n",
    "        filter_used = filter_dict\n",
    "    \n",
    "    # 2. Retrieve documents\n",
    "    docs = vector_store.similarity_search(question, **search_kwargs)\n",
    "    \n",
    "    # 3. Format context\n",
    "    context = \"\"\n",
    "    for i, doc in enumerate(docs):\n",
    "        context += f\"\\nDocument {i+1} (Episode {doc.metadata.get('episode')}):\\n{doc.page_content}\\n\"\n",
    "    \n",
    "    # 4. Build prompt\n",
    "    prompt = f\"\"\"You are a helpful assistant that answers questions strictly based on podcast transcripts.\n",
    "\n",
    "You will be given a set of retrieved transcript excerpts as context.  \n",
    "Use ONLY this context to answer the question.  \n",
    "If the answer cannot be found or inferred from the context, say:  \n",
    "\"I do not have enough information from the provided context to answer.\"\n",
    "\n",
    "Guidelines:\n",
    "- Cite or reference relevant parts of the context in your reasoning.\n",
    "- Do NOT invent facts, add details not in the context, or rely on prior general knowledge.\n",
    "- If the question asks for something outside the given context, acknowledge the limitation.\n",
    "- Provide concise, factual, and direct answers.\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "    # 5. Get answer\n",
    "    response = llm.invoke(prompt).content\n",
    "    \n",
    "    return response, docs, filter_used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "edc97e00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:\n",
      "\"This American Life\" is a popular public radio program in the United States, created by Ira Glass. The show features a unique format that combines narrative storytelling with journalism, exploring various themes and issues in American life. Each episode typically revolves around a specific theme and includes a series of stories from different contributors, which can be personal anecdotes, reported stories, or creative pieces.\n",
      "\n",
      "The show covers a wide range of topics, from the mundane to the profound, touching on everything from human relationships to societal issues. What sets \"This American Life\" apart is its emphasis on storytelling, often using real-life experiences to highlight broader cultural or social concepts. The show has garnered numerous awards and has a dedicated following, making it a significant part of American media culture since its debut in 1995.\n",
      "\n",
      "--------------------------------------------------\n",
      "Context Used:\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "query = \"what is this american life about\"\n",
    "answer, source_docs, filter_used = ask_podcast_rag(query)\n",
    "\n",
    "if filter_used:\n",
    "    print(f\"Applying metadata filter: {filter_used}\")\n",
    "\n",
    "# Clean up the response to ensure consistent formatting\n",
    "final_answer = answer.strip()\n",
    "if final_answer.startswith(\"Answer:\"):\n",
    "    final_answer = final_answer[len(\"Answer:\"):].strip()\n",
    "\n",
    "print(\"Answer:\")\n",
    "print(final_answer)\n",
    "print()\n",
    "print(\"-\" * 50)\n",
    "\n",
    "print(\"Context Used:\")\n",
    "for i, doc in enumerate(source_docs):\n",
    "    print(f\"Document {i+1} (Episode {doc.metadata.get('episode')}):\")\n",
    "    print(doc.page_content)\n",
    "    print()\n",
    "print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b16d62ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting evaluation on 13 questions...\n",
      "\n",
      "Test 1: What is the title of episode 462 of This American Life?\n",
      "  RAG: correct\n",
      "  RAG: correct\n",
      "  Vanilla: wrong\n",
      "\n",
      "Test 2: What is the title of episode 449 of This American Life?\n",
      "  Vanilla: wrong\n",
      "\n",
      "Test 2: What is the title of episode 449 of This American Life?\n",
      "  RAG: wrong\n",
      "  RAG: wrong\n",
      "  Vanilla: wrong\n",
      "\n",
      "Test 3: Which episode is titled 'In Defense of Ignorance'?\n",
      "  Vanilla: wrong\n",
      "\n",
      "Test 3: Which episode is titled 'In Defense of Ignorance'?\n",
      "  RAG: correct\n",
      "  RAG: correct\n",
      "  Vanilla: wrong\n",
      "\n",
      "Test 4: Which show is hosted by the program described as a weekly public radio program produced by WBEZ Chicago and syndicated by PRX?\n",
      "  Vanilla: wrong\n",
      "\n",
      "Test 4: Which show is hosted by the program described as a weekly public radio program produced by WBEZ Chicago and syndicated by PRX?\n",
      "  RAG: correct\n",
      "  RAG: correct\n",
      "  Vanilla: correct\n",
      "\n",
      "Test 5: What is the original name of 'This American Life' when it first aired in 1995?\n",
      "  Vanilla: correct\n",
      "\n",
      "Test 5: What is the original name of 'This American Life' when it first aired in 1995?\n",
      "  RAG: wrong\n",
      "  RAG: wrong\n",
      "  Vanilla: correct\n",
      "\n",
      "Test 6: Who's the host of this american life podcast\n",
      "  Vanilla: correct\n",
      "\n",
      "Test 6: Who's the host of this american life podcast\n",
      "  RAG: correct\n",
      "  RAG: correct\n",
      "  Vanilla: correct\n",
      "\n",
      "Test 7: What is the episode number of 'In Defense of Ignorance'?\n",
      "  Vanilla: correct\n",
      "\n",
      "Test 7: What is the episode number of 'In Defense of Ignorance'?\n",
      "  RAG: correct\n",
      "  RAG: correct\n",
      "  Vanilla: wrong\n",
      "\n",
      "Test 8: Which This American Life episode archive page indicates that transcripts become available the week after broadcast?\n",
      "  Vanilla: wrong\n",
      "\n",
      "Test 8: Which This American Life episode archive page indicates that transcripts become available the week after broadcast?\n",
      "  RAG: wrong\n",
      "  RAG: wrong\n",
      "  Vanilla: wrong\n",
      "\n",
      "Test 9: Who is the interviewee in the prologue of Episode 1?\n",
      "  Vanilla: wrong\n",
      "\n",
      "Test 9: Who is the interviewee in the prologue of Episode 1?\n",
      "  RAG: correct\n",
      "  RAG: correct\n",
      "  Vanilla: wrong\n",
      "\n",
      "Test 10: In Episode 200, which government department hired a former ad executive to run an information campaign?\n",
      "  Vanilla: wrong\n",
      "\n",
      "Test 10: In Episode 200, which government department hired a former ad executive to run an information campaign?\n",
      "  RAG: correct\n",
      "  RAG: correct\n",
      "  Vanilla: wrong\n",
      "\n",
      "Test 11: In Episode 500, what object does Ira Glass compare the milestone to clicking over?\n",
      "  Vanilla: wrong\n",
      "\n",
      "Test 11: In Episode 500, what object does Ira Glass compare the milestone to clicking over?\n",
      "  RAG: correct\n",
      "  RAG: correct\n",
      "  Vanilla: correct\n",
      "\n",
      "Test 12: Which office does Gordon Johndroe speak for in Act One of episode 227?\n",
      "  Vanilla: correct\n",
      "\n",
      "Test 12: Which office does Gordon Johndroe speak for in Act One of episode 227?\n",
      "  RAG: correct\n",
      "  RAG: correct\n",
      "  Vanilla: wrong\n",
      "\n",
      "Test 13: According to Sarah Koenig, why might the plants grow well in one area of her yard in episode 396\n",
      "  Vanilla: wrong\n",
      "\n",
      "Test 13: According to Sarah Koenig, why might the plants grow well in one area of her yard in episode 396\n",
      "  RAG: correct\n",
      "  RAG: correct\n",
      "  Vanilla: wrong\n",
      "--------------------------------------------------\n",
      "Final Results:\n",
      "RAG Accuracy:     76.9%\n",
      "Vanilla Accuracy: 30.8%\n",
      "--------------------------------------------------\n",
      "  Vanilla: wrong\n",
      "--------------------------------------------------\n",
      "Final Results:\n",
      "RAG Accuracy:     76.9%\n",
      "Vanilla Accuracy: 30.8%\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "golden_set = [\n",
    "    {\n",
    "        \"question\": \"What is the title of episode 462 of This American Life?\",\n",
    "        \"ground_truth\": \"Own Worst Enemy\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What is the title of episode 449 of This American Life?\",\n",
    "        \"ground_truth\": \"Middle School\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Which episode is titled 'In Defense of Ignorance'?\",\n",
    "        \"ground_truth\": \"585\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Which show is hosted by the program described as a weekly public radio program produced by WBEZ Chicago and syndicated by PRX?\",\n",
    "        \"ground_truth\": \"This American Life\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What is the original name of 'This American Life' when it first aired in 1995?\",\n",
    "        \"ground_truth\": \"Your Radio Playhouse\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Who's the host of this american life podcast\",\n",
    "        \"ground_truth\": \"Ira Glass\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What is the episode number of 'In Defense of Ignorance'?\",\n",
    "        \"ground_truth\": \"585\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Which This American Life episode archive page indicates that transcripts become available the week after broadcast?\",\n",
    "        \"ground_truth\": \"FAQ page\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Who is the interviewee in the prologue of Episode 1?\",\n",
    "        \"ground_truth\": \"Joe Franklin\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"In Episode 200, which government department hired a former ad executive to run an information campaign?\",\n",
    "        \"ground_truth\": \"US State Department\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"In Episode 500, what object does Ira Glass compare the milestone to clicking over?\",\n",
    "        \"ground_truth\": \"odometer\"\n",
    "    },\n",
    "    {\"question\": \"Which office does Gordon Johndroe speak for in Act One of episode 227?\", \n",
    "     \"ground_truth\": \"White House Office of Homeland Security\"    \n",
    "    },\n",
    "    \n",
    "    {\"question\": \"According to Sarah Koenig, why might the plants grow well in one area of her yard in episode 396\",\n",
    "     \"ground_truth\": \"peeing\"\n",
    "     }\n",
    "]\n",
    "\n",
    "def ask_vanilla_llm(question):\n",
    "    \"\"\"Asks the LLM without any retrieved context.\"\"\"\n",
    "    prompt = f\"\"\"You are a helpful assistant. Answer the following question to the best of your ability.\n",
    "    \n",
    "    Question: {question}\n",
    "    \"\"\"\n",
    "    return llm.invoke(prompt).content\n",
    "\n",
    "def grade_answer(question, ground_truth, prediction):\n",
    "    \"\"\"\n",
    "    Grades the answer based on string matching rules:\n",
    "    1. Exact match (case-insensitive, stripped)\n",
    "    2. Ground truth is a substring of prediction\n",
    "    3. Prediction is a substring of ground truth\n",
    "    4. All words in ground truth appear in prediction\n",
    "    \"\"\"\n",
    "    gt_norm = ground_truth.lower().strip()\n",
    "    pred_norm = prediction.lower().strip()\n",
    "    \n",
    "    # 1. Exact match\n",
    "    if gt_norm == pred_norm:\n",
    "        return True\n",
    "        \n",
    "    # 2. Ground truth is substring of prediction\n",
    "    if gt_norm in pred_norm:\n",
    "        return True\n",
    "        \n",
    "    # 3. Prediction is substring of ground truth\n",
    "    if pred_norm in gt_norm:\n",
    "        return True\n",
    "        \n",
    "    # 4. All words in ground truth appear in prediction\n",
    "    gt_words = set(gt_norm.split())\n",
    "    pred_words = set(pred_norm.split())\n",
    "    if gt_words.issubset(pred_words):\n",
    "        return True\n",
    "        \n",
    "    return False\n",
    "\n",
    "\n",
    "# 2. Run Evaluation\n",
    "results = []\n",
    "print(f\"Starting evaluation on {len(golden_set)} questions...\")\n",
    "\n",
    "for i, item in enumerate(golden_set):\n",
    "    q = item[\"question\"]\n",
    "    gt = item[\"ground_truth\"]\n",
    "    \n",
    "    print(f\"\\nTest {i+1}: {q}\")\n",
    "    \n",
    "    # Test RAG\n",
    "    # Note: ask_podcast_rag returns (response, docs, filter_used)\n",
    "    rag_ans, _, _ = ask_podcast_rag(q)\n",
    "    rag_correct = grade_answer(q, gt, rag_ans)\n",
    "    print(f\"  RAG: {'correct' if rag_correct else 'wrong'}\")\n",
    "    \n",
    "    # Test Vanilla\n",
    "    vanilla_ans = ask_vanilla_llm(q)\n",
    "    vanilla_correct = grade_answer(q, gt, vanilla_ans)\n",
    "    print(f\"  Vanilla: {'correct' if vanilla_correct else 'wrong'}\")\n",
    "    \n",
    "    results.append({\n",
    "        \"question\": q,\n",
    "        \"ground_truth\": gt,\n",
    "        \"rag_correct\": rag_correct,\n",
    "        \"vanilla_correct\": vanilla_correct,\n",
    "        \"rag_ans\": rag_ans,\n",
    "        \"vanilla_ans\": vanilla_ans\n",
    "    })\n",
    "\n",
    "# 3. Calculate Metrics\n",
    "rag_accuracy = sum(1 for r in results if r[\"rag_correct\"]) / len(results) * 100\n",
    "vanilla_accuracy = sum(1 for r in results if r[\"vanilla_correct\"]) / len(results) * 100\n",
    "\n",
    "print(\"-\" * 50)\n",
    "print(f\"Final Results:\")\n",
    "print(f\"RAG Accuracy:     {rag_accuracy:.1f}%\")\n",
    "print(f\"Vanilla Accuracy: {vanilla_accuracy:.1f}%\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Print failures to analyze\n",
    "# print(\"\\nAnalysis of RAG Failures:\")\n",
    "# for r in results:\n",
    "#     if not r[\"rag_correct\"]:\n",
    "#         print(f\"Q: {r['question']}\")\n",
    "#         print(f\"Expected: {r['ground_truth']}\")\n",
    "#         print(f\"Got: {r['rag_ans']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b458fc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
