{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5286928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD EXISTING VECTOR DATABASE\n",
    "import os\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "import chromadb\n",
    "\n",
    "# 1. Define the path to the existing database\n",
    "persist_dir = os.path.join(os.getcwd(), \"../models/tal_chroma\")\n",
    "print(f\"Loading ChromaDB from: {persist_dir}\")\n",
    "\n",
    "# 2. Initialize the embedding function\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-small\",\n",
    "    openai_api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    ")\n",
    "\n",
    "# 3. Connect to the persistent client\n",
    "client = chromadb.PersistentClient(path=persist_dir)\n",
    "\n",
    "# 4. Load the vector store\n",
    "vector_store = Chroma(\n",
    "    client=client,\n",
    "    collection_name=\"tal_collection\",\n",
    "    embedding_function=embeddings,\n",
    ")\n",
    "\n",
    "print(\"Vector store loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9795fc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_core.documents import Document\n",
    "from typing import List, Dict, Any\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import tiktoken\n",
    "import chromadb\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51584acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain openai chromadb tiktoken jq python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2fe77ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Joe Franklin?' metadata={'source': '/Users/matthewlu/Downloads/podcast-RAG/data/transcripts_full.json', 'seq_num': 1, 'episode': 'ep-1', 'role': 'interviewer', 'speaker': 'ira glass', 'act': 'prologue', 'utterance_start': 0.17, 'utterance_end': 0.58}\n"
     ]
    }
   ],
   "source": [
    "print(docs[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "102cfaaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='I'm ready.' metadata={'source': '/Users/matthewlu/Downloads/podcast-RAG/data/transcripts_full.json', 'seq_num': 2, 'episode': 'ep-1', 'role': 'subject', 'speaker': 'joe franklin', 'act': 'prologue', 'utterance_start': 0.58, 'utterance_end': 1.39}\n"
     ]
    }
   ],
   "source": [
    "print(docs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46a20a31",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vector_store' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m docs \u001b[38;5;241m=\u001b[39m vector_store\u001b[38;5;241m.\u001b[39msimilarity_search(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn episode 462, what did Ira Glass and Steve Blass talk about?\u001b[39m\u001b[38;5;124m\"\u001b[39m, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m docs:\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(d\u001b[38;5;241m.\u001b[39mmetadata)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'vector_store' is not defined"
     ]
    }
   ],
   "source": [
    "docs = vector_store.similarity_search(\"In episode 462, what did Ira Glass and Steve Blass talk about?\", k=3)\n",
    "for d in docs:\n",
    "    print(d.metadata)\n",
    "    print(d.page_content[:500], \"...\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f915168e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tokens across 28642 chunks: 10993831\n"
     ]
    }
   ],
   "source": [
    "tokenizer = tiktoken.encoding_for_model(\"text-embedding-3-small\")\n",
    "\n",
    "# chunked_docs is a list of Document objects, but encode expects a string.\n",
    "# We need to iterate and encode the page_content of each doc.\n",
    "total_tokens = 0\n",
    "for doc in chunked_docs:\n",
    "    total_tokens += len(tokenizer.encode(doc.page_content))\n",
    "\n",
    "print(f\"Total tokens across {len(chunked_docs)} chunks: {total_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d7eed03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nt/6nrb_d696ylb20nhdcw60rfc0000gn/T/ipykernel_4967/3497629341.py:1: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  llm = ChatOpenAI(\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model_name=\"gpt-4o-mini\",\n",
    "    temperature=1,\n",
    "    openai_api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    verbose=False,\n",
    "    streaming=False\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca53d5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def ask_podcast_rag(question: str):\n",
    "    # 1. Try to extract an episode number for metadata filtering\n",
    "    # This helps the vector store narrow down to the specific episode\n",
    "    search_kwargs = {\"k\": 10}\n",
    "    \n",
    "    # Regex to find \"episode <number>\"\n",
    "    match = re.search(r\"episode\\s+(\\d+)\", question, re.IGNORECASE)\n",
    "    filter_used = None\n",
    "    if match:\n",
    "        ep_num = match.group(1)\n",
    "        # Construct the ID format used in your metadata (e.g., \"ep-462\")\n",
    "        filter_dict = {\"episode\": f\"ep-{ep_num}\"}\n",
    "        search_kwargs[\"filter\"] = filter_dict\n",
    "        filter_used = filter_dict\n",
    "    \n",
    "    # 2. Retrieve documents\n",
    "    docs = vector_store.similarity_search(question, **search_kwargs)\n",
    "    \n",
    "    # 3. Format context\n",
    "    context = \"\"\n",
    "    for i, doc in enumerate(docs):\n",
    "        context += f\"\\nDocument {i+1} (Episode {doc.metadata.get('episode')}):\\n{doc.page_content}\\n\"\n",
    "    \n",
    "    # 4. Build prompt\n",
    "    prompt = f\"\"\"You are a helpful assistant answering questions about podcast transcripts.\n",
    "Use the following context, and also general knowledge to answer the question.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "    # 5. Get answer\n",
    "    response = llm.predict(prompt)\n",
    "    \n",
    "    return response, docs, filter_used\n",
    "\n",
    "# Example usage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "edc97e00",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vector_store' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn Episode 500, what object does Ira Glass compare the milestone to clicking over?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m answer, source_docs, filter_used \u001b[38;5;241m=\u001b[39m ask_podcast_rag(query)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filter_used:\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mApplying metadata filter: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilter_used\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[7], line 19\u001b[0m, in \u001b[0;36mask_podcast_rag\u001b[0;34m(question)\u001b[0m\n\u001b[1;32m     16\u001b[0m     filter_used \u001b[38;5;241m=\u001b[39m filter_dict\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# 2. Retrieve documents\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m docs \u001b[38;5;241m=\u001b[39m vector_store\u001b[38;5;241m.\u001b[39msimilarity_search(question, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msearch_kwargs)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# 3. Format context\u001b[39;00m\n\u001b[1;32m     22\u001b[0m context \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'vector_store' is not defined"
     ]
    }
   ],
   "source": [
    "query = \"In Episode 500, what object does Ira Glass compare the milestone to clicking over?\"\n",
    "answer, source_docs, filter_used = ask_podcast_rag(query)\n",
    "\n",
    "if filter_used:\n",
    "    print(f\"Applying metadata filter: {filter_used}\")\n",
    "\n",
    "# Clean up the response to ensure consistent formatting\n",
    "final_answer = answer.strip()\n",
    "if final_answer.startswith(\"Answer:\"):\n",
    "    final_answer = final_answer[len(\"Answer:\"):].strip()\n",
    "\n",
    "print(\"Answer:\")\n",
    "print(final_answer)\n",
    "print()\n",
    "print(\"-\" * 50)\n",
    "\n",
    "print(\"Context Used:\")\n",
    "for i, doc in enumerate(source_docs):\n",
    "    print(f\"Document {i+1} (Episode {doc.metadata.get('episode')}):\")\n",
    "    print(doc.page_content)\n",
    "    print()\n",
    "print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "b16d62ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting evaluation on 11 questions...\n",
      "\n",
      "Test 1: What is the title of episode 462 of This American Life?\n",
      "  RAG: ✅\n",
      "  RAG: ✅\n",
      "  Vanilla: ❌\n",
      "\n",
      "Test 2: What is the title of episode 449 of This American Life?\n",
      "  Vanilla: ❌\n",
      "\n",
      "Test 2: What is the title of episode 449 of This American Life?\n",
      "  RAG: ❌\n",
      "  RAG: ❌\n",
      "  Vanilla: ❌\n",
      "\n",
      "Test 3: Which episode is titled 'In Defense of Ignorance'?\n",
      "  Vanilla: ❌\n",
      "\n",
      "Test 3: Which episode is titled 'In Defense of Ignorance'?\n",
      "  RAG: ✅\n",
      "  RAG: ✅\n",
      "  Vanilla: ❌\n",
      "\n",
      "Test 4: Which show is hosted by the program described as a weekly public radio program produced by WBEZ Chicago and syndicated by PRX?\n",
      "  Vanilla: ❌\n",
      "\n",
      "Test 4: Which show is hosted by the program described as a weekly public radio program produced by WBEZ Chicago and syndicated by PRX?\n",
      "  RAG: ✅\n",
      "  RAG: ✅\n",
      "  Vanilla: ✅\n",
      "\n",
      "Test 5: What is the original name of 'This American Life' when it first aired in 1995?\n",
      "  Vanilla: ✅\n",
      "\n",
      "Test 5: What is the original name of 'This American Life' when it first aired in 1995?\n",
      "  RAG: ❌\n",
      "  RAG: ❌\n",
      "  Vanilla: ❌\n",
      "\n",
      "Test 6: As of 2025, who is listed as the host of This American Life?\n",
      "  Vanilla: ❌\n",
      "\n",
      "Test 6: As of 2025, who is listed as the host of This American Life?\n",
      "  RAG: ✅\n",
      "  RAG: ✅\n",
      "  Vanilla: ✅\n",
      "\n",
      "Test 7: What is the episode number of 'In Defense of Ignorance'?\n",
      "  Vanilla: ✅\n",
      "\n",
      "Test 7: What is the episode number of 'In Defense of Ignorance'?\n",
      "  RAG: ✅\n",
      "  RAG: ✅\n",
      "  Vanilla: ❌\n",
      "\n",
      "Test 8: Which This American Life episode archive page indicates that transcripts become available the week after broadcast?\n",
      "  Vanilla: ❌\n",
      "\n",
      "Test 8: Which This American Life episode archive page indicates that transcripts become available the week after broadcast?\n",
      "  RAG: ❌\n",
      "  RAG: ❌\n",
      "  Vanilla: ✅\n",
      "\n",
      "Test 9: Who is the interviewee in the prologue of Episode 1?\n",
      "  Vanilla: ✅\n",
      "\n",
      "Test 9: Who is the interviewee in the prologue of Episode 1?\n",
      "  RAG: ✅\n",
      "  RAG: ✅\n",
      "  Vanilla: ❌\n",
      "\n",
      "Test 10: In Episode 200, which government department hired a former ad executive to run an information campaign?\n",
      "  Vanilla: ❌\n",
      "\n",
      "Test 10: In Episode 200, which government department hired a former ad executive to run an information campaign?\n",
      "  RAG: ✅\n",
      "  RAG: ✅\n",
      "  Vanilla: ❌\n",
      "\n",
      "Test 11: In Episode 500, what object does Ira Glass compare the milestone to clicking over?\n",
      "  Vanilla: ❌\n",
      "\n",
      "Test 11: In Episode 500, what object does Ira Glass compare the milestone to clicking over?\n",
      "  RAG: ✅\n",
      "  RAG: ✅\n",
      "  Vanilla: ✅\n",
      "--------------------------------------------------\n",
      "Final Results:\n",
      "RAG Accuracy:     72.7%\n",
      "Vanilla Accuracy: 36.4%\n",
      "--------------------------------------------------\n",
      "  Vanilla: ✅\n",
      "--------------------------------------------------\n",
      "Final Results:\n",
      "RAG Accuracy:     72.7%\n",
      "Vanilla Accuracy: 36.4%\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "golden_set = [\n",
    "    {\n",
    "        \"question\": \"What is the title of episode 462 of This American Life?\",\n",
    "        \"ground_truth\": \"Own Worst Enemy\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What is the title of episode 449 of This American Life?\",\n",
    "        \"ground_truth\": \"Middle School\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Which episode is titled 'In Defense of Ignorance'?\",\n",
    "        \"ground_truth\": \"585\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Which show is hosted by the program described as a weekly public radio program produced by WBEZ Chicago and syndicated by PRX?\",\n",
    "        \"ground_truth\": \"This American Life\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What is the original name of 'This American Life' when it first aired in 1995?\",\n",
    "        \"ground_truth\": \"Your Radio Playhouse\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"As of 2025, who is listed as the host of This American Life?\",\n",
    "        \"ground_truth\": \"Ira Glass\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What is the episode number of 'In Defense of Ignorance'?\",\n",
    "        \"ground_truth\": \"585\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Which This American Life episode archive page indicates that transcripts become available the week after broadcast?\",\n",
    "        \"ground_truth\": \"FAQ page\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Who is the interviewee in the prologue of Episode 1?\",\n",
    "        \"ground_truth\": \"Joe Franklin\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"In Episode 200, which government department hired a former ad executive to run an information campaign?\",\n",
    "        \"ground_truth\": \"US State Department\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"In Episode 500, what object does Ira Glass compare the milestone to clicking over?\",\n",
    "        \"ground_truth\": \"odometer\"\n",
    "    }\n",
    "]\n",
    "\n",
    "def ask_vanilla_llm(question):\n",
    "    \"\"\"Asks the LLM without any retrieved context.\"\"\"\n",
    "    prompt = f\"\"\"You are a helpful assistant. Answer the following question to the best of your ability.\n",
    "    \n",
    "    Question: {question}\n",
    "    \"\"\"\n",
    "    return llm.predict(prompt)\n",
    "\n",
    "def grade_answer(question, ground_truth, prediction):\n",
    "    \"\"\"\n",
    "    Grades the answer based on string matching rules:\n",
    "    1. Exact match (case-insensitive, stripped)\n",
    "    2. Ground truth is a substring of prediction\n",
    "    3. Prediction is a substring of ground truth\n",
    "    4. All words in ground truth appear in prediction\n",
    "    \"\"\"\n",
    "    gt_norm = ground_truth.lower().strip()\n",
    "    pred_norm = prediction.lower().strip()\n",
    "    \n",
    "    # 1. Exact match\n",
    "    if gt_norm == pred_norm:\n",
    "        return True\n",
    "        \n",
    "    # 2. Ground truth is substring of prediction\n",
    "    if gt_norm in pred_norm:\n",
    "        return True\n",
    "        \n",
    "    # 3. Prediction is substring of ground truth\n",
    "    if pred_norm in gt_norm:\n",
    "        return True\n",
    "        \n",
    "    # 4. All words in ground truth appear in prediction\n",
    "    gt_words = set(gt_norm.split())\n",
    "    pred_words = set(pred_norm.split())\n",
    "    if gt_words.issubset(pred_words):\n",
    "        return True\n",
    "        \n",
    "    return False\n",
    "\n",
    "# 2. Run Evaluation\n",
    "results = []\n",
    "print(f\"Starting evaluation on {len(golden_set)} questions...\")\n",
    "\n",
    "for i, item in enumerate(golden_set):\n",
    "    q = item[\"question\"]\n",
    "    gt = item[\"ground_truth\"]\n",
    "    \n",
    "    print(f\"\\nTest {i+1}: {q}\")\n",
    "    \n",
    "    # Test RAG\n",
    "    # Note: ask_podcast_rag returns (response, docs, filter_used)\n",
    "    rag_ans, _, _ = ask_podcast_rag(q)\n",
    "    rag_correct = grade_answer(q, gt, rag_ans)\n",
    "    print(f\"  RAG: {'✅' if rag_correct else '❌'}\")\n",
    "    \n",
    "    # Test Vanilla\n",
    "    vanilla_ans = ask_vanilla_llm(q)\n",
    "    vanilla_correct = grade_answer(q, gt, vanilla_ans)\n",
    "    print(f\"  Vanilla: {'✅' if vanilla_correct else '❌'}\")\n",
    "    \n",
    "    results.append({\n",
    "        \"question\": q,\n",
    "        \"ground_truth\": gt,\n",
    "        \"rag_correct\": rag_correct,\n",
    "        \"vanilla_correct\": vanilla_correct,\n",
    "        \"rag_ans\": rag_ans,\n",
    "        \"vanilla_ans\": vanilla_ans\n",
    "    })\n",
    "\n",
    "# 3. Calculate Metrics\n",
    "rag_accuracy = sum(1 for r in results if r[\"rag_correct\"]) / len(results) * 100\n",
    "vanilla_accuracy = sum(1 for r in results if r[\"vanilla_correct\"]) / len(results) * 100\n",
    "\n",
    "print(\"-\" * 50)\n",
    "print(f\"Final Results:\")\n",
    "print(f\"RAG Accuracy:     {rag_accuracy:.1f}%\")\n",
    "print(f\"Vanilla Accuracy: {vanilla_accuracy:.1f}%\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Optional: Print failures to analyze\n",
    "# print(\"\\nAnalysis of RAG Failures:\")\n",
    "# for r in results:\n",
    "#     if not r[\"rag_correct\"]:\n",
    "#         print(f\"Q: {r['question']}\")\n",
    "#         print(f\"Expected: {r['ground_truth']}\")\n",
    "#         print(f\"Got: {r['rag_ans']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b458fc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
